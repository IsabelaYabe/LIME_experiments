{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Isas_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import Lasso\n",
    "# Importar bibliotecas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Explicador LIME\n",
    "import lime\n",
    "import lime.lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instância: Nunca vi algo tão ruim na minha vida. A produção foi amadora e a história, entediante.\n",
      "Rótulo: 0\n",
      "[array([0, 1, 1, 1, 1, 0, 1, 1, 1, 1]), array([1, 1, 0, 1, 1, 0, 0, 0, 1, 1]), array([0, 1, 1, 0, 0, 1, 1, 0, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de conjunto de dados de resenhas\n",
    "dados = pd.read_csv('dados.csv', sep=';')\n",
    "\n",
    "# Separar as features e o alvo\n",
    "X = dados['review']\n",
    "y = dados['sentimentos']\n",
    "\n",
    "# Escolher uma instância para fazer a previsão\n",
    "instance_index = 15\n",
    "instance = X.iloc[instance_index]\n",
    "instance_label = y.iloc[instance_index]\n",
    "print('Instância:', instance)\n",
    "print('Rótulo:', instance_label)\n",
    "print([np.random.randint(2, size = 10) for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirar stop-words\n",
    "stop_words = stopwords.words('portuguese')\n",
    "X_sw = X.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "# Vetorização do texto\n",
    "vectorizer_sw = TfidfVectorizer()\n",
    "X_vectorized_sw = vectorizer_sw.fit_transform(X_sw)\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train_sw, X_test_sw, y_train, y_test = train_test_split(X_vectorized_sw, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!\n",
      "foi\n",
      "  (0, 125)\t0.33409972762024637\n",
      "  (0, 182)\t0.4023535870696947\n",
      "  (0, 248)\t0.3876307185009198\n",
      "  (0, 40)\t0.4023535870696947\n",
      "  (0, 219)\t0.2711927452342461\n",
      "  (0, 124)\t0.3259287506501664\n",
      "  (0, 175)\t0.4044076630246902\n",
      "  (0, 163)\t0.266500218652219\n",
      "não\n",
      "(98,)\n",
      "(98, 256)\n"
     ]
    }
   ],
   "source": [
    "# Deixar stopwords\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "print(\"!\"*20)\n",
    "#print(vectorizer.get_feature_names_out())\n",
    "print(vectorizer.get_feature_names_out()[118])\n",
    "#print(vectorizer.get_feature_names_out()[54])\n",
    "#print(vectorizer.get_feature_names_out()[246])\n",
    "#print(vectorizer.get_feature_names_out()[65])\n",
    "#print(vectorizer.get_feature_names_out()[239])\n",
    "#print(vectorizer.get_feature_names_out()[230])\n",
    "#print(vectorizer.get_feature_names_out()[217])\n",
    "#print(\"-\"*20)\n",
    "#print(X_vectorized[1][0])\n",
    "#print(X[1])\n",
    "print(X_vectorized[59][0])\n",
    "print(vectorizer.get_feature_names_out()[175])\n",
    "print(X.shape)\n",
    "print(X_vectorized.shape)\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importancia(W: np.array) -> np.array:\n",
    "    I = np.zeros(W.shape[1])  # Vetor de importância\n",
    "    for j in range(W.shape[1]):\n",
    "        soma = np.sum(np.abs(W[:, j]))\n",
    "        I[j] = np.sqrt(soma)\n",
    "    return I\n",
    "\n",
    "def c(V: list, W: np.array, I: np.array) -> float:\n",
    "    c_value = 0  # Valor de c\n",
    "    for j in range(W.shape[1]):\n",
    "        if any(W[i, j] > 0 for i in V):  # Se a característica j é relevante\n",
    "            c_value += I[j]\n",
    "    return c_value\n",
    "\n",
    "def guloso(W: np.array, I: np.array, B: int) -> list:\n",
    "    nao_selecionados = list(range(W.shape[0]))  # Lista de índices não selecionados\n",
    "    V = []  # Conjunto de características selecionadas\n",
    "    itens = 0  # Número de elementos selecionados\n",
    "    c_value = 0  # Valor de c\n",
    "    \n",
    "    while itens < B and nao_selecionados:\n",
    "        best_gain = -np.inf  # Valor de ganho máximo\n",
    "        best_item = None  # Índice do melhor item \n",
    "        \n",
    "        for item in nao_selecionados:  # Itera sobre os itens não selecionados\n",
    "            lista_temp = V + [item]\n",
    "            gain = c(lista_temp, W, I) - c(V, W, I)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain  # Atualiza o valor de ganho máximo\n",
    "                best_item = item  # Atualiza o melhor item\n",
    "        \n",
    "        if best_item is not None:\n",
    "            V.append(best_item)  # Adiciona o melhor item ao conjunto\n",
    "            nao_selecionados.remove(best_item)  # Remove o melhor item dos não selecionados\n",
    "            itens += 1\n",
    "            c_value += best_gain\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de importância:  [2.  2.  2.2]\n",
      "Cobertura:  6.23606797749979\n",
      "Melhor conjunto:  [0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "W = np.array([[1, 2, 1], [-1, 0, 2], [-2, 2, -2]])  # Exemplo de matriz W\n",
    "I = importancia(W)\n",
    "print(\"Matriz de importância: \", I)\n",
    "\n",
    "V = [0, 1]  # Lista de índices das instâncias selecionadas\n",
    "print(\"Cobertura: \", c(V, W, I))\n",
    "\n",
    "V_linha = guloso(W, I, 2)\n",
    "print(\"Melhor conjunto: \", V_linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.zeros(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não gostei. Muito chato e sem graça. Não vale a pena.\n",
      "chato gostei graça muito não pena sem vale\n"
     ]
    }
   ],
   "source": [
    "x = X_vectorized[59]\n",
    "print(X[59])\n",
    "def binarize(x):\n",
    "    n = len(vectorizer.get_feature_names_out())\n",
    "    x_bin=np.zeros(n, dtype=int)\n",
    "    for i in x.indices:\n",
    "        x_bin[i] = 1\n",
    "    return x_bin\n",
    "num_samples = 5\n",
    "n = len(vectorizer.get_feature_names_out())\n",
    "x_indices = x.indices\n",
    "n_x_words = len(x.indices)    \n",
    "sample_set = [np.zeros(n) for i in range(num_samples-1)]\n",
    "sample_set.append(binarize(x))\n",
    "for i in range(num_samples-1):\n",
    "    z_line_indices = np.random.randint(2, size=n_x_words)\n",
    "    while not np.any(z_line_indices):  \n",
    "        z_line_indices = np.random.randint(2, size=n_x_words)\n",
    "    z_line_indices = np.where(z_line_indices == 1)[0]\n",
    "    activated_words = [x_indices[j] for j in z_line_indices]\n",
    "    sample_set[i][activated_words] = 1\n",
    "\n",
    "indices = np.where(binarize(x)== 1)[0]\n",
    "z=\" \".join([vectorizer.get_feature_names_out()[indice] for indice in indices])\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LimeExplainerSentences:\n",
    "    def __init__(self, sigma=0.2, num_samples=1000, K=5, alpha=0.1**(-5), p =10,vectorizer=None, model=None):\n",
    "        self.sigma = sigma\n",
    "        self.num_samples = num_samples\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.p = p\n",
    "        self.model = model\n",
    "        self.vectorizer = vectorizer\n",
    "    \n",
    "    # Binarizar vetor de palavras\n",
    "    def binarize(self, x):\n",
    "        np.set_printoptions(precision=self.p)\n",
    "        n = len(self.vectorizer.get_feature_names_out())\n",
    "        x_bin=np.zeros(n, dtype=int)\n",
    "        for i in x.indices:\n",
    "            x_bin[i] = 1\n",
    "        return x_bin\n",
    "\n",
    "    # Define a função de kernel \n",
    "    def kernel(self, x, z):\n",
    "        np.set_printoptions(precision=self.p)\n",
    "        distance = cosine_similarity(x, z) # Similaridade de cosseno\n",
    "        pi_x = np.sqrt(np.exp(-(distance**2) / (self.sigma**2)))  # Kernel \n",
    "        return pi_x\n",
    "        \n",
    "    # Gera dados ao redor de x_line\n",
    "    def samples(self, x):\n",
    "        np.set_printoptions(precision=self.p)\n",
    "        n = len(self.vectorizer.get_feature_names_out())\n",
    "        x_indices = x.indices\n",
    "        n_x_words = len(x.indices)    \n",
    "        sample_set = [np.zeros(n) for i in range(self.num_samples-1)]\n",
    "        sample_set.append(self.binarize(x))\n",
    "        for i in range(self.num_samples-1):\n",
    "            z_line_indices = np.random.randint(2, size=n_x_words)\n",
    "            while not np.any(z_line_indices):\n",
    "                z_line_indices = np.random.randint(2, size=n_x_words)\n",
    "            z_line_indices = np.where(z_line_indices == 1)[0]\n",
    "            activated_words = [x_indices[j] for j in z_line_indices]\n",
    "            sample_set[i][activated_words] = 1\n",
    "        return sample_set\n",
    "    \n",
    "    # Transforma um vetor em uma frase\n",
    "    def sentences_samples(self, z_line):\n",
    "        np.set_printoptions(precision=self.p)\n",
    "        indices = np.where(z_line == 1)[0]\n",
    "        z=\" \".join([self.vectorizer.get_feature_names_out()[indice] for indice in indices])\n",
    "        return self.vectorizer.transform([z])\n",
    "\n",
    "    # Define o vetor de pesos\n",
    "    def LIME(self, x):\n",
    "        np.set_printoptions(precision=self.p)\n",
    "        Z_line = self.samples(x)\n",
    "        Z=[]\n",
    "        for i in range(len(Z_line)):\n",
    "            Z.append(self.sentences_samples(Z_line[i]))\n",
    "        Z_pred = np.array([self.model.predict(z)[0] for z in Z])  \n",
    "        pi_x = np.array([self.kernel(x, z)[0][0] for z in Z]) \n",
    "        lasso = Lasso(alpha=self.alpha)\n",
    "        lasso.fit(Z_line, Z_pred, sample_weight=pi_x)\n",
    "        w = lasso.coef_\n",
    "        return w \n",
    "\n",
    "    # Gerar explicação\n",
    "    def explain_instance(self, x):\n",
    "        w = self.LIME(x)\n",
    "        abs_valores = np.abs(w)\n",
    "        indices = np.argsort(abs_valores)[::-1][:self.K]\n",
    "        print(\"Palavras importantes:\")\n",
    "        for i in indices:\n",
    "            print(f\"{self.vectorizer.get_feature_names_out()[i]}: {w[i]}\")    \n",
    "\n",
    "\n",
    "class SubmodularPick:\n",
    "    def __init__(self,X_n_vec, X, B,lime=None, vectorizer=None):\n",
    "        self.X_n_vec = X_n_vec\n",
    "        self.X = X\n",
    "        self.B = B\n",
    "        self.lime = lime\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def explain_instances(self, X):\n",
    "        W = [self.lime.LIME(x) for x in X] \n",
    "        return np.array(W)      \n",
    "        \n",
    "    def importancia(self, W):\n",
    "        I = np.zeros(W.shape[1])  \n",
    "        for j in range(W.shape[1]):\n",
    "            soma = np.sum(np.abs(W[:, j]))\n",
    "            I[j] = np.sqrt(soma)\n",
    "        return I\n",
    "\n",
    "    def cobertura(self, V, W, I):\n",
    "        c_value = 0  \n",
    "        for j in range(W.shape[1]):\n",
    "            if any(W[i, j] > 0 for i in V):  # Se a característica j é relevante\n",
    "                c_value += I[j]\n",
    "        return c_value\n",
    "\n",
    "    def guloso(self, X, B):\n",
    "        W = self.explain_instances(X) \n",
    "        I = self.importancia(W)\n",
    "        nao_selecionados = list(range(W.shape[0]))  # Lista de índices não selecionados\n",
    "        V = []  # Conjunto de características selecionadas\n",
    "        itens = 0  # Número de elementos selecionados\n",
    "        c_value = 0  # Valor de c\n",
    "\n",
    "        while itens < B and nao_selecionados:\n",
    "            best_gain = -np.inf  # Valor de ganho máximo\n",
    "            best_item = None  # Índice do melhor item \n",
    "\n",
    "            for item in nao_selecionados:  # Itera sobre os itens não selecionados\n",
    "                lista_temp = V + [item]\n",
    "                gain = self.cobertura(lista_temp, W, I) - self.cobertura(V, W, I)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain  # Atualiza o valor de ganho máximo\n",
    "                    best_item = item  # Atualiza o melhor item\n",
    "\n",
    "            if best_item is not None:\n",
    "                V.append(best_item)  # Adiciona o melhor item ao conjunto\n",
    "                nao_selecionados.remove(best_item)  # Remove o melhor item dos não selecionados\n",
    "                itens += 1\n",
    "                c_value += best_gain\n",
    "\n",
    "        return V\n",
    "    \n",
    "    def explain_model(self, X):\n",
    "        V = self.guloso(X, self.B)\n",
    "        print(\"Melhor conjunto de explicação: \", V)\n",
    "        for i in V:\n",
    "            print(f\"{self.X_n_vec[i]}\")\n",
    "        print(\"Fim da explicação\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instância:  [ 80   7 179 223 216   5 221 155 196 114]\n",
      "Instância:  Nunca vi algo tão ruim na minha vida. A produção foi amadora e a história, entediante.\n",
      "Rótulo:  0\n",
      "Palavras importantes:\n",
      "produção: -0.1464034577358566\n",
      "amadora: -0.09535542184737185\n",
      "nunca: -0.08093087602826937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Isas_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de explicação:  [59, 13, 94, 0, 1, 2, 3, 4, 5, 6]\n",
      "Não gostei. Muito chato graça. Não vale pena.\n",
      "Enredo fraco atuações piores ainda. Não recomendo filme ninguém.\n",
      "Não esperava isso, impossível parar assistir.\n",
      "Este filme absolutamente incrível! A trama envolvente atuações dignas Oscar.\n",
      "Um desperdício total tempo. O roteiro fraco direção deixa desejar.\n",
      "O roteiro bem escrito atores entregaram performances memoráveis realmente emocionaram.\n",
      "Não gostei nada trama. Foi previsível personagens profundidade.\n",
      "Uma obra-prima cinematográfica captura essência drama humano. Vou assistir novo.\n",
      "Terrível. A pior experiência cinema. Os diálogos artificiais emoção.\n",
      "Gostei bastante direção fotografia. Cada cena cuidadosamente elaborada.\n",
      "Fim da explicação\n"
     ]
    }
   ],
   "source": [
    "# Retirar stop-words\n",
    "stop_words = stopwords.words('portuguese')\n",
    "X_sw = X.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "# Vetorização do texto\n",
    "vectorizer_sw = TfidfVectorizer()\n",
    "X_vectorized_sw = vectorizer_sw.fit_transform(X_sw)\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train_sw, X_test_sw, y_train, y_test = train_test_split(X_vectorized_sw, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinamento do modelo de Gradient Boosting\n",
    "gb_model_sw = GradientBoostingClassifier(random_state=42)\n",
    "gb_model_sw.fit(X_train_sw, y_train)\n",
    "# Separar as features e o alvo\n",
    "instance_index = 15\n",
    "\n",
    "x = X_vectorized_sw[instance_index]\n",
    "print(\"Instância: \", x.indices)\n",
    "print(\"Instância: \", instance)\n",
    "print(\"Rótulo: \", instance_label)\n",
    "\n",
    "LIME = LimeExplainerSentences(sigma=0.1, num_samples=5000, K=3, alpha=0.1**(5), p=1, vectorizer=vectorizer_sw, model=gb_model_sw)\n",
    "LIME.explain_instance(x)\n",
    "\n",
    "submodular = SubmodularPick(X_sw, X_vectorized_sw, 10, lime=LIME, vectorizer=vectorizer_sw)\n",
    "submodular.explain_model(X_vectorized_sw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
