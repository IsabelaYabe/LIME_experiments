{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Isas_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import Lasso\n",
    "# Importar bibliotecas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Explicador LIME\n",
    "import lime\n",
    "import lime.lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instância: Nunca vi algo tão ruim na minha vida. A produção foi amadora e a história, entediante.\n",
      "Rótulo: 0\n",
      "[array([0, 0, 1, 0, 1, 1, 1, 1, 0, 1]), array([0, 1, 0, 1, 1, 0, 0, 1, 0, 1]), array([0, 0, 0, 0, 1, 1, 1, 1, 1, 0])]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de conjunto de dados de resenhas\n",
    "dados = pd.read_csv('dados.csv', sep=';')\n",
    "\n",
    "# Separar as features e o alvo\n",
    "X = dados['review']\n",
    "y = dados['sentimentos']\n",
    "\n",
    "# Escolher uma instância para fazer a previsão\n",
    "instance_index = 15\n",
    "instance = X.iloc[instance_index]\n",
    "instance_label = y.iloc[instance_index]\n",
    "print('Instância:', instance)\n",
    "print('Rótulo:', instance_label)\n",
    "print([np.random.randint(2, size = 10) for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirar stop-words\n",
    "stop_words = stopwords.words('portuguese')\n",
    "X_sw = X.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "# Vetorização do texto\n",
    "vectorizer_sw = TfidfVectorizer()\n",
    "X_vectorized_sw = vectorizer_sw.fit_transform(X_sw)\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train_sw, X_test_sw, y_train, y_test = train_test_split(X_vectorized_sw, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([0, 1, 0, 1, 0])\n",
    "print(np.where(a==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 54  65 230]\n",
      "Não gostei. Muito chato e sem graça. Não vale a pena.\n",
      "[163 175 124 219  40 248 182 125]\n",
      "65\n",
      "0.0\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "[163 175 124 219  40 248 182 125]\n",
      "!!!!!!!!!!!!!!!!!!!!\n",
      "['absolutamente' 'achei' 'acrescentaram' 'adorei' 'ainda' 'algo'\n",
      " 'altamente' 'amadora' 'amei' 'anterior' 'ao' 'aos' 'apreciam' 'arte'\n",
      " 'artificiais' 'as' 'assisti' 'assistindo' 'assistir' 'atento' 'atenção'\n",
      " 'ator' 'atores' 'atuação' 'atuações' 'até' 'bastante' 'bela' 'belas'\n",
      " 'bem' 'bom' 'brilhante' 'cabeça' 'cada' 'cadeira' 'captura' 'cativam'\n",
      " 'cativante' 'cena' 'cenas' 'chato' 'chatos' 'cheio' 'cinema'\n",
      " 'cinematográfica' 'com' 'começo' 'complementa' 'conectar' 'confusa'\n",
      " 'confuso' 'consegui' 'cuidadosamente' 'da' 'de' 'decepcionante' 'deixa'\n",
      " 'deixou' 'deles' 'desde' 'desejar' 'desenvolvida' 'desenvolvidos'\n",
      " 'desinteressados' 'desinteressante' 'desperdício' 'deste' 'detalhe'\n",
      " 'dias' 'dignas' 'direção' 'dirigido' 'diálogos' 'do' 'dos' 'drama'\n",
      " 'efeitos' 'elaborada' 'em' 'emocional' 'emocionante' 'emocionantes'\n",
      " 'emocionaram' 'emoção' 'encantador' 'encontrar' 'enredo' 'enrendo'\n",
      " 'entediado' 'entediante' 'entender' 'entregaram' 'envolvente' 'envolver'\n",
      " 'eram' 'escrito' 'especiais' 'espectador' 'esperava' 'espetacular'\n",
      " 'essência' 'este' 'eu' 'excepcionais' 'executado' 'experiência'\n",
      " 'extremamente' 'fantástica' 'fantástico' 'fascinante' 'faz' 'feito'\n",
      " 'feitos' 'filme' 'filmes' 'fim' 'final' 'fiquei' 'foi' 'foram'\n",
      " 'fotografia' 'fraca' 'fraco' 'gostar' 'gostei' 'graça' 'história'\n",
      " 'horrível' 'humano' 'impecáveis' 'impecável' 'importar' 'impossível'\n",
      " 'incrível' 'inesperadas' 'inesquecível' 'ingresso' 'inspiradora'\n",
      " 'intrigante' 'início' 'irritantes' 'isso' 'jornada' 'já' 'lento' 'lindo'\n",
      " 'magnífico' 'mais' 'mal' 'mantiveram' 'mantêm' 'maravilhosa'\n",
      " 'maravilhoso' 'me' 'melhores' 'memoráveis' 'mensagem' 'merece' 'minha'\n",
      " 'minuto' 'momento' 'momentos' 'motivação' 'muito' 'na' 'nada' 'narrativa'\n",
      " 'nem' 'nenhum' 'nenhuma' 'neste' 'ninguém' 'no' 'novo' 'nunca' 'não'\n",
      " 'obra' 'os' 'oscar' 'para' 'parar' 'pareciam' 'pena' 'perca' 'perda'\n",
      " 'perfeitamente' 'performances' 'personagens' 'pior' 'piores' 'planejada'\n",
      " 'ponta' 'pontos' 'por' 'porcaria' 'prende' 'prendeu' 'previsível' 'prima'\n",
      " 'produzido' 'produção' 'profunda' 'profundidade' 'prêmios' 'pé' 'péssimo'\n",
      " 'público' 'qualidade' 'que' 'raro' 'realmente' 'recomendo' 'recomendável'\n",
      " 'redentora' 'refletindo' 'ressoa' 'reviravoltas' 'roteiro' 'ruim' 'sem'\n",
      " 'sentido' 'seu' 'seus' 'simplesmente' 'sonora' 'superficiais'\n",
      " 'surpreendeu' 'surpresas' 'são' 'te' 'tempo' 'terminar' 'terrível'\n",
      " 'tinham' 'tive' 'tocante' 'tocantes' 'todo' 'todos' 'total' 'totalmente'\n",
      " 'trama' 'trilha' 'trouxe' 'tudo' 'tão' 'um' 'uma' 'vale' 'verdadeira'\n",
      " 'vi' 'viciante' 'vida' 'visual' 'vou' 'vários']\n",
      "  (0, 163)\t0.266500218652219\n",
      "  (0, 175)\t0.4044076630246902\n",
      "  (0, 124)\t0.3259287506501664\n",
      "  (0, 219)\t0.2711927452342461\n",
      "  (0, 40)\t0.4023535870696947\n",
      "  (0, 248)\t0.3876307185009198\n",
      "  (0, 182)\t0.4023535870696947\n",
      "  (0, 125)\t0.33409972762024637\n",
      "não\n",
      "(98,)\n",
      "(98, 256)\n"
     ]
    }
   ],
   "source": [
    "# Deixar stopwords\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "print(vectorizer.transform(['desperdício de tempo']).indices)\n",
    "print(X[59])\n",
    "print(X_vectorized[59].indices)\n",
    "index = vectorizer.vocabulary_.get(\"desperdício\")\n",
    "print(index)\n",
    "print(X_vectorized[59, index])\n",
    "print(\"!\"*20)\n",
    "a = X_vectorized[59].indices\n",
    "\n",
    "print(a)\n",
    "print(\"!\"*20)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "#print(vectorizer.get_feature_names_out()[118])\n",
    "#print(vectorizer.get_feature_names_out()[54])\n",
    "#print(vectorizer.get_feature_names_out()[246])\n",
    "#print(vectorizer.get_feature_names_out()[65])\n",
    "#print(vectorizer.get_feature_names_out()[239])\n",
    "#print(vectorizer.get_feature_names_out()[230])\n",
    "#print(vectorizer.get_feature_names_out()[217])\n",
    "#print(\"-\"*20)\n",
    "#print(X_vectorized[1][0])\n",
    "#print(X[1])\n",
    "print(X_vectorized[59][0])\n",
    "print(vectorizer.get_feature_names_out()[175])\n",
    "print(X.shape)\n",
    "print(X_vectorized.shape)\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importancia(W: np.array) -> np.array:\n",
    "    I = np.zeros(W.shape[1])  # Vetor de importância\n",
    "    for j in range(W.shape[1]):\n",
    "        soma = np.sum(np.abs(W[:, j]))\n",
    "        I[j] = np.sqrt(soma)\n",
    "    return I\n",
    "\n",
    "def c(V: list, W: np.array, I: np.array) -> float:\n",
    "    c_value = 0  # Valor de c\n",
    "    for j in range(W.shape[1]):\n",
    "        if any(W[i, j] > 0 for i in V):  # Se a característica j é relevante\n",
    "            c_value += I[j]\n",
    "    return c_value\n",
    "\n",
    "def guloso(W: np.array, I: np.array, B: int) -> list:\n",
    "    nao_selecionados = list(range(W.shape[0]))  # Lista de índices não selecionados\n",
    "    V = []  # Conjunto de características selecionadas\n",
    "    itens = 0  # Número de elementos selecionados\n",
    "    c_value = 0  # Valor de c\n",
    "    \n",
    "    while itens < B and nao_selecionados:\n",
    "        best_gain = -np.inf  # Valor de ganho máximo\n",
    "        best_item = None  # Índice do melhor item \n",
    "        \n",
    "        for item in nao_selecionados:  # Itera sobre os itens não selecionados\n",
    "            lista_temp = V + [item]\n",
    "            gain = c(lista_temp, W, I) - c(V, W, I)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain  # Atualiza o valor de ganho máximo\n",
    "                best_item = item  # Atualiza o melhor item\n",
    "        \n",
    "        if best_item is not None:\n",
    "            V.append(best_item)  # Adiciona o melhor item ao conjunto\n",
    "            nao_selecionados.remove(best_item)  # Remove o melhor item dos não selecionados\n",
    "            itens += 1\n",
    "            c_value += best_gain\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de importância:  [2.           2.           2.2360679775]\n",
      "Cobertura:  6.23606797749979\n",
      "Melhor conjunto:  [0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "W = np.array([[1, 2, 1], [-1, 0, 2], [-2, 2, -2]])  # Exemplo de matriz W\n",
    "I = importancia(W)\n",
    "print(\"Matriz de importância: \", I)\n",
    "\n",
    "V = [0, 1]  # Lista de índices das instâncias selecionadas\n",
    "print(\"Cobertura: \", c(V, W, I))\n",
    "\n",
    "V_linha = guloso(W, I, 2)\n",
    "print(\"Melhor conjunto: \", V_linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.zeros(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não gostei. Muito chato e sem graça. Não vale a pena.\n",
      "chato gostei graça muito não pena sem vale\n"
     ]
    }
   ],
   "source": [
    "x = X_vectorized[59]\n",
    "print(X[59])\n",
    "def binarize(x):\n",
    "    n = len(vectorizer.get_feature_names_out())\n",
    "    x_bin=np.zeros(n, dtype=int)\n",
    "    for i in x.indices:\n",
    "        x_bin[i] = 1\n",
    "    return x_bin\n",
    "num_samples = 5\n",
    "n = len(vectorizer.get_feature_names_out())\n",
    "x_indices = x.indices\n",
    "n_x_words = len(x.indices)    \n",
    "sample_set = [np.zeros(n) for i in range(num_samples-1)]\n",
    "sample_set.append(binarize(x))\n",
    "for i in range(num_samples-1):\n",
    "    z_line_indices = np.random.randint(2, size=n_x_words)\n",
    "    while not np.any(z_line_indices):  \n",
    "        z_line_indices = np.random.randint(2, size=n_x_words)\n",
    "    z_line_indices = np.where(z_line_indices == 1)[0]\n",
    "    activated_words = [x_indices[j] for j in z_line_indices]\n",
    "    sample_set[i][activated_words] = 1\n",
    "\n",
    "indices = np.where(binarize(x)== 1)[0]\n",
    "z=\" \".join([vectorizer.get_feature_names_out()[indice] for indice in indices])\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LimeExplainerSentences:\n",
    "    def __init__(self, sigma=0.2, num_samples=1000, K=5, alpha=0.1, vectorizer=None, model=None):\n",
    "        self.sigma = sigma\n",
    "        self.num_samples = num_samples\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.model = model\n",
    "        self.vectorizer = vectorizer\n",
    "    \n",
    "    # Binarizar vetor de palavras\n",
    "    def binarize(self, x):\n",
    "        n = len(vectorizer.get_feature_names_out())\n",
    "        x_bin=np.zeros(n, dtype=int)\n",
    "        for i in x.indices:\n",
    "            x_bin[i] = 1\n",
    "        return x_bin\n",
    "\n",
    "    # Define a função de kernel \n",
    "    def kernel(self, x, z):\n",
    "        distance = cosine_similarity(x, z) # Similaridade de cosseno\n",
    "        weights = np.sqrt(np.exp(-(distance**2) / (self.sigma**2)))  # Kernel \n",
    "        return weights\n",
    "        \n",
    "    # Gera dados ao redor de x_line\n",
    "    def samples(self, x):\n",
    "        n = len(vectorizer.get_feature_names_out())\n",
    "        x_indices = x.indices\n",
    "        n_x_words = len(x.indices)    \n",
    "        sample_set = [np.zeros(n) for i in range(self.num_samples-1)]\n",
    "        sample_set.append(self.binarize(x))\n",
    "        for i in range(self.num_samples-1):\n",
    "            z_line_indices = np.random.randint(2, size=n_x_words)\n",
    "            while not np.any(z_line_indices):  \n",
    "                z_line_indices = np.random.randint(2, size=n_x_words)\n",
    "            z_line_indices = np.where(z_line_indices == 1)[0]\n",
    "            activated_words = [x_indices[j] for j in z_line_indices]\n",
    "            sample_set[i][activated_words] = 1\n",
    "        return sample_set\n",
    "    \n",
    "    # Transforma um vetor em uma frase\n",
    "    def sentences_samples(self, z_line):\n",
    "        indices = np.where(z_line == 1)[0]\n",
    "        z=\" \".join([vectorizer.get_feature_names_out()[indice] for indice in indices])\n",
    "        return vectorizer.transform(z)\n",
    "\n",
    "    # Define o vetor de pesos\n",
    "    def LIME(self, x):\n",
    "        Z_line = self.samples(x)\n",
    "        print(Z_line)\n",
    "        print(len(Z_line))\n",
    "        Z=[]\n",
    "        for i in range(len(Z_line)):\n",
    "            Z.append(self.sentences_samples(Z_line[i]))\n",
    "        Z_pred = [self.model.predict(z) for z in Z]\n",
    "        pi_x = []\n",
    "        for z in Z:\n",
    "            pi_x.append(self.kernel(x, z)) \n",
    "        lasso = Lasso(alpha=self.alpha)\n",
    "        lasso.fit(Z_line, Z_pred, sample_weight=pi_x)\n",
    "        w = lasso.coef_\n",
    "        return w\n",
    "    \n",
    "    def K_top_indices(self, x):\n",
    "        abs_valores = np.abs(w)\n",
    "\n",
    "    # Gerar explicação\n",
    "    def explain_instance(self, x):\n",
    "        w = self.LIME(x)\n",
    "        abs_valores = np.abs(w)\n",
    "        indices = np.argsort(abs_valores)[::-1][:self.K]\n",
    "        print(f\"Frase: {x}\")\n",
    "        print(f\"w: {w}\")\n",
    "        print(\"Palavras importantes:\")\n",
    "        for i, word in enumerate(x):\n",
    "            if i in indices:\n",
    "                print(f\"{word}: {w[i]}\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento do modelo de Gradient Boosting\n",
    "gb_model_sw = GradientBoostingClassifier(random_state=42)\n",
    "gb_model_sw.fit(X_train_sw, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instância:  [118 126 218 174 250   5 245 164 158 252 200   7  89]\n",
      "Instância:  Nunca vi algo tão ruim na minha vida. A produção foi amadora e a história, entediante.\n",
      "Rótulo:  0\n",
      "[array([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0.]), array([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0])]\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[164], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRótulo: \u001b[39m\u001b[38;5;124m\"\u001b[39m, instance_label)\n\u001b[0;32m     20\u001b[0m LIME \u001b[38;5;241m=\u001b[39m LimeExplainerSentences(sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, vectorizer\u001b[38;5;241m=\u001b[39mvectorizer, model\u001b[38;5;241m=\u001b[39mgb_model_sw)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mLIME\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[163], line 66\u001b[0m, in \u001b[0;36mLimeExplainerSentences.explain_instance\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexplain_instance\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 66\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLIME\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     abs_valores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(w)\n\u001b[0;32m     68\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(abs_valores)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK]\n",
      "Cell \u001b[1;32mIn[163], line 51\u001b[0m, in \u001b[0;36mLimeExplainerSentences.LIME\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(Z_line)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(Z_line))\n\u001b[1;32m---> 51\u001b[0m Z \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentences_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_line\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m z_line \u001b[38;5;129;01min\u001b[39;00m Z_line]\n\u001b[0;32m     52\u001b[0m Z_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(z) \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m Z]\n\u001b[0;32m     53\u001b[0m pi_x \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[163], line 44\u001b[0m, in \u001b[0;36mLimeExplainerSentences.sentences_samples\u001b[1;34m(self, z_line)\u001b[0m\n\u001b[0;32m     42\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(z_line \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     43\u001b[0m z\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out()[indice] \u001b[38;5;28;01mfor\u001b[39;00m indice \u001b[38;5;129;01min\u001b[39;00m indices])\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\feature_extraction\\text.py:2117\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[0;32m   2101\u001b[0m \n\u001b[0;32m   2102\u001b[0m \u001b[38;5;124;03mUses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2113\u001b[0m \u001b[38;5;124;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   2114\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2115\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2117\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mtransform(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\feature_extraction\\text.py:1413\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m \n\u001b[0;32m   1399\u001b[0m \u001b[38;5;124;03mExtract token counts out of raw text documents using the vocabulary\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;124;03m    Document-term matrix.\u001b[39;00m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_documents, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1414\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterable over raw text documents expected, string object received.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1415\u001b[0m     )\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_vocabulary()\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "# Retirar stop-words\n",
    "stop_words = stopwords.words('portuguese')\n",
    "X_sw = X.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "# Vetorização do texto\n",
    "vectorizer_sw = TfidfVectorizer()\n",
    "X_vectorized_sw = vectorizer_sw.fit_transform(X_sw)\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train_sw, X_test_sw, y_train, y_test = train_test_split(X_vectorized_sw, y, test_size=0.2, random_state=42)\n",
    "# Separar as features e o alvo\n",
    "instance_index = 15\n",
    "instance = X.iloc[instance_index]\n",
    "instance_label = y.iloc[instance_index]\n",
    "x = X_vectorized[instance_index]\n",
    "print(\"Instância: \", x.indices)\n",
    "print(\"Instância: \", instance)\n",
    "print(\"Rótulo: \", instance_label)\n",
    "\n",
    "LIME = LimeExplainerSentences(sigma=0.1, num_samples=2, K=3, alpha=0.1, vectorizer=vectorizer, model=gb_model_sw)\n",
    "LIME.explain_instance(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
